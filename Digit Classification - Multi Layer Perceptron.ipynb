{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79897bab",
   "metadata": {},
   "source": [
    "The model works as follows:-\n",
    "-It contains a input layer X1 (100,784)\n",
    "-It is multiplied to a 500-d matrix containing the weights W1(784,500)\n",
    "-The  bias B1(500) - a zero matrix - is added to the result and saved in Y1(100,500)\n",
    "-The function is made non-linear by applying the relu activation function on Y1 and the result is saved in X2(100,500)\n",
    "-Again, X2 is multiplied to a different set of weights W2(500,10) and another bias B2(10) is added to the result.\n",
    "-The result is saved into Y2 (100,10).\n",
    "-Y2 is sent through the softmax activation function(inbuilt in cross entropy loss) to calculate the probabilities of each.\n",
    "-The gradients of all the parameters requiring gradients is computed and the optimizer is called upon to set those gradients.\n",
    "*This the end of the training phase.*\n",
    "-In the testing phase, the labels are compared with the predictions and the accuracy of the model is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271db77",
   "metadata": {},
   "source": [
    "Steps:-\n",
    "1)Import the dependencies\n",
    "2)Load the Data into testing and training sets\n",
    "3)Divide it into mini batches \n",
    "*Until this point everything is same as logistic regression*\n",
    "4)Initialize the parameters - 2 sets of weights and 2 sets of biases - make sure to set requires_grad = True for all\n",
    "5)Assign the optimizer - SGD\n",
    "6)Train the model by iterating through the mini - batches\n",
    "7)Test the model using the test mini-batches\n",
    "8)Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3a50e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65fb57aa15d40b09460f09382a4c1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over.\n",
      "\n",
      "Testing Phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854bb4eb4c624c518715c98bb5959b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over.\n",
      "\n",
      "The accuracy of the multi-layered perceptron model is: 96.1500015258789 %\n"
     ]
    }
   ],
   "source": [
    "#Imporating Dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "        \n",
    "\n",
    "#Loading Data\n",
    "mnist_train = datasets.MNIST(root = './datasets', train = True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = datasets.MNIST(root = './datasets', train = False, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "#Distributing Data\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size = 100, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size = 100, shuffle = False)\n",
    "\n",
    "#Initialize Parameters \n",
    "W1 = (torch.randn(784,500))*2/np.sqrt(784)\n",
    "W1.requires_grad_()\n",
    "W2 = (torch.randn(500,10))*2/np.sqrt(500)\n",
    "W2.requires_grad_()\n",
    "B1 = torch.zeros(500, requires_grad = True)\n",
    "B2 = torch.zeros(10, requires_grad = True)\n",
    "\n",
    "#Optimizer\n",
    "optimizer = torch.optim.SGD([W1,W2,B1,B2], lr = 0.7)\n",
    "\n",
    "#Training \n",
    "print('Traning Phase...')\n",
    "for images,labels in tqdm(train_loader):\n",
    "    #clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Forward pass\n",
    "    X1 = images.view(-1, 28*28)\n",
    "    Y1 = torch.matmul(X1,W1) + B1\n",
    "    #Relu\n",
    "    X2 = torch.max(torch.zeros_like(Y1),Y1)\n",
    "    \n",
    "    Y2 = torch.matmul(X2,W2) + B2\n",
    "    \n",
    "    #Calculating loss\n",
    "    ce_loss = F.cross_entropy(Y2,labels)\n",
    "    \n",
    "    #Backward pass\n",
    "    ce_loss.backward()\n",
    "    optimizer.step()\n",
    "print('Training Over.\\n')\n",
    "\n",
    "#Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "print('Testing Phase...')\n",
    "for image, label in tqdm(test_loader):\n",
    "    x1 = image.view(-1,28*28)\n",
    "    y1 = torch.matmul(x1,W1) + B1\n",
    "    x2 = F.relu(y1)\n",
    "    y2 = torch.matmul(x2, W2) + B2\n",
    "    pred = torch.argmax(y2, dim = 1)\n",
    "    correct += torch.sum((pred == label).float())\n",
    "print('Testing Over.\\n')\n",
    "\n",
    "#Calculating Accuracy\n",
    "print('The accuracy of the multi-layered perceptron model is: {} %'.format(correct*100/total))\n",
    "# Make sure to print out your accuracy on the test set at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71540c64",
   "metadata": {},
   "source": [
    "Using Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a1b0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad32d3653e547ffa9e983fd80b8555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over.\n",
      "\n",
      "Testing Phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55742c91d20f412fb174b85af9f777df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over.\n",
      "\n",
      "The accuracy of the multi-layered perceptron model is: 96.04000091552734 %\n"
     ]
    }
   ],
   "source": [
    "#Imporating Dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "        \n",
    "\n",
    "#Loading Data\n",
    "mnist_train = datasets.MNIST(root = './datasets', train = True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = datasets.MNIST(root = './datasets', train = False, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "#Distributing Data\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size = 100, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size = 100, shuffle = False)\n",
    "\n",
    "#Defining the training classes\n",
    "class ModelTrain:\n",
    "    \n",
    "    def __init__(self,row,col):\n",
    "        self.W = (torch.randn(row,col))*2/np.sqrt(row)\n",
    "        self.W.requires_grad_()\n",
    "        self.B = torch.zeros(col, requires_grad = True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return torch.matmul(x,self.W) + self.B\n",
    "    \n",
    "#Instantiating the layers of the model\n",
    "layer_1 = ModelTrain(784,500)\n",
    "layer_2 = ModelTrain(500,10)\n",
    "\n",
    "#Optimizer\n",
    "optimizer = torch.optim.SGD([layer_1.W,layer_1.B,layer_2.W,layer_2.B], lr = 0.7)\n",
    "\n",
    "#Training \n",
    "print('Traning Phase...')\n",
    "\n",
    "for images,labels in tqdm(train_loader):\n",
    "    #clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Forward pass\n",
    "    X1 = images.view(-1, 28*28)\n",
    "    \n",
    "    #Layer-1\n",
    "    Y1 = layer_1.forward(X1)\n",
    "    \n",
    "    #Relu\n",
    "    X2 = F.relu(Y1)\n",
    "    \n",
    "    #Layer-2\n",
    "    Y2 = layer_2.forward(X2)\n",
    "    \n",
    "    #Calculating loss\n",
    "    ce_loss = F.cross_entropy(Y2,labels)\n",
    "    \n",
    "    #Backward pass\n",
    "    ce_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print('Training Over.\\n')\n",
    "\n",
    "#Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "print('Testing Phase...')\n",
    "\n",
    "for image, label in tqdm(test_loader):\n",
    "    \n",
    "    X1 = image.view(-1,28*28)\n",
    "    Y1 = layer_1.forward(X1)\n",
    "    \n",
    "    X2 = F.relu(Y1)\n",
    "    Y2 = layer_2.forward(X2)\n",
    "    \n",
    "    pred = torch.argmax(Y2, dim = 1)\n",
    "    correct += torch.sum((pred == label).float())\n",
    "    \n",
    "print('Testing Over.\\n')\n",
    "\n",
    "#Calculating Accuracy\n",
    "print('The accuracy of the multi-layered perceptron model is: {} %'.format(correct*100/total))\n",
    "# Make sure to print out your accuracy on the test set at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ab536",
   "metadata": {},
   "source": [
    "Using Higher Level API (torch.nn module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be33159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a5cb2f58b74aa6a57d8dbc70cec8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over!\n",
      "Testing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cff50c6a344be4b33b342047ebd569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over!\n",
      "The accuracy of the Multi-Layered Perceptron model is: 96.44000244140625 %\n"
     ]
    }
   ],
   "source": [
    "#Importing dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Loading datasets\n",
    "mnist_train = datasets.MNIST(root = './databases', train= True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = datasets.MNIST(root = './databases', train= False, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "#Distributing Data\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size = 100, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size = 100, shuffle = False)\n",
    "\n",
    "#Defining the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(784,500)\n",
    "        self.layer_2 = nn.Linear(500,10)\n",
    "    \n",
    "    def layer1(self,x):\n",
    "        y = self.layer_1(x)\n",
    "        return F.relu(y)\n",
    "    \n",
    "    def layer2(self,x):\n",
    "        return self.layer_2(x)\n",
    "    \n",
    "#Instantiating the model\n",
    "model = MLP()\n",
    "\n",
    "#Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.6)\n",
    "\n",
    "#Training\n",
    "print('Training...')\n",
    "\n",
    "for images,labels in tqdm(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    x1 = images.view(-1,28*28)\n",
    "    x2 = model.layer1(x1)\n",
    "    y = model.layer2(x2)\n",
    "    \n",
    "    loss = F.cross_entropy(y,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print('Training Over!')\n",
    "\n",
    "#Testing\n",
    "print('Testing...')\n",
    "\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "for images, labels in tqdm(test_loader):\n",
    "    x1 = images.view(-1,28*28)\n",
    "    x2 = model.layer1(x1)\n",
    "    y = model.layer2(x2)\n",
    "    \n",
    "    pred = torch.argmax(y, dim = 1)\n",
    "    correct += torch.sum((pred == labels).float())\n",
    "    \n",
    "print('Testing Over!')\n",
    "\n",
    "print('The accuracy of the Multi-Layered Perceptron model is: {} %'.format(correct*100/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc99c20",
   "metadata": {},
   "source": [
    "Adding some more hidden layers - Doesn't work any better than in case of a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba483e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7369d29f15471b85f3a0747fc2e59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over!\n",
      "Testing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afebdbdcc45040248e04a2f4e1e4bdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over!\n",
      "The accuracy of the Multi-Layered Perceptron model is: 95.0999984741211 %\n"
     ]
    }
   ],
   "source": [
    "#Importing dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Loading datasets\n",
    "mnist_train = datasets.MNIST(root = './databases', train= True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = datasets.MNIST(root = './databases', train= False, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "#Distributing Data\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size = 100, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size = 100, shuffle = False)\n",
    "\n",
    "#Defining the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(784,500)\n",
    "        self.layer_2 = nn.Linear(500,1000)\n",
    "        self.layer_3 = nn.Linear(1000,10)\n",
    "    \n",
    "    def layer1(self,x):\n",
    "        y = self.layer_1(x)\n",
    "        return F.relu(y)\n",
    "    \n",
    "    def layer2(self,x):\n",
    "        y = self.layer_2(x)\n",
    "        return F.relu(y)\n",
    "    \n",
    "    def layer3(self,x):\n",
    "        return self.layer_3(x)\n",
    "    \n",
    "#Instantiating the model\n",
    "model = MLP()\n",
    "\n",
    "#Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.25)\n",
    "\n",
    "#Training\n",
    "print('Training...')\n",
    "\n",
    "for images,labels in tqdm(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    x1 = images.view(-1,28*28)\n",
    "    x2 = model.layer1(x1)\n",
    "    x3 = model.layer2(x2)\n",
    "    y  = model.layer3(x3)\n",
    "    \n",
    "    loss = F.cross_entropy(y,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print('Training Over!')\n",
    "\n",
    "#Testing\n",
    "print('Testing...')\n",
    "\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "for images, labels in tqdm(test_loader):\n",
    "    x1 = images.view(-1,28*28)\n",
    "    x2 = model.layer1(x1)\n",
    "    x3 = model.layer2(x2)\n",
    "    y  = model.layer3(x3)\n",
    "    \n",
    "    pred = torch.argmax(y, dim = 1)\n",
    "    correct += torch.sum((pred == labels).float())\n",
    "    \n",
    "print('Testing Over!')\n",
    "\n",
    "print('The accuracy of the Multi-Layered Perceptron model is: {} %'.format(correct*100/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf28921",
   "metadata": {},
   "source": [
    "Method to estimate the best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec063af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The learning rate for the iteration is -  0.1\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cc6f7e776042c7813df7aed8a06223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over!\n",
      "Testing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6f97c0c0634d9dab084ef87c682f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over!\n",
      "The accuracy of the Multi-Layered Perceptron model is: 92.5 %\n",
      "\n",
      "The learning rate for the iteration is -  0.15000000000000002\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5094ecbf91f94d6d9046bcf3ea232309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over!\n",
      "Testing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb36e116673b4b9187164dbd0e8e9a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over!\n",
      "The accuracy of the Multi-Layered Perceptron model is: 95.08999633789062 %\n",
      "\n",
      "The learning rate for the iteration is -  0.2\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f538cd37d8e4b5f8907944d764de6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over!\n",
      "Testing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1330f9241dae47318575fac9bba80380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over!\n",
      "The accuracy of the Multi-Layered Perceptron model is: 96.38999938964844 %\n",
      "\n",
      "The learning rate for the iteration is -  0.25\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aa1352c4cc442ba7e733d91c472415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over!\n",
      "Testing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4959f2fe34344be1bb24dbbfc9f1b6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over!\n",
      "The accuracy of the Multi-Layered Perceptron model is: 97.19000244140625 %\n",
      "Accuracy Achieved! at 0.25.\n",
      "\n",
      " {0.25: 97.19000244140625, 0.2: 96.38999938964844, 0.15000000000000002: 95.08999633789062, 0.1: 92.5} \n",
      "\n",
      "The best learning rate is 0.25\n"
     ]
    }
   ],
   "source": [
    "#Importing dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import operator as op\n",
    "#Loading datasets\n",
    "mnist_train = datasets.MNIST(root = './databases', train= True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = datasets.MNIST(root = './databases', train= False, transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "\n",
    "#Defining the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(784,500)\n",
    "        self.layer_2 = nn.Linear(500,1000)\n",
    "        self.layer_3 = nn.Linear(1000,10)\n",
    "\n",
    "    def layer1(self,x):\n",
    "        y = self.layer_1(x)\n",
    "        return F.relu(y)\n",
    "\n",
    "    def layer2(self,x):\n",
    "        y = self.layer_2(x)\n",
    "        return F.relu(y)\n",
    "\n",
    "    def layer3(self,x):\n",
    "        return self.layer_3(x)\n",
    "        \n",
    "#Distributing Data\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size = 100, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size = 100, shuffle = False)\n",
    "\n",
    "#Instantiating the model\n",
    "model = MLP()\n",
    "    \n",
    "#Initiating learning rate \n",
    "l_r = 0.1\n",
    "d = {}\n",
    "\n",
    "while True:\n",
    "    print('\\nThe learning rate for the iteration is - ', l_r)\n",
    "    \n",
    "    #Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = l_r)\n",
    "\n",
    "    #Training\n",
    "    print('Training...')\n",
    "\n",
    "    for images,labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x1 = images.view(-1,28*28)\n",
    "        x2 = model.layer1(x1)\n",
    "        x3 = model.layer2(x2)\n",
    "        y  = model.layer3(x3)\n",
    "\n",
    "        loss = F.cross_entropy(y,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Training Over!')\n",
    "\n",
    "    #Testing\n",
    "    print('Testing...')\n",
    "\n",
    "    correct = 0\n",
    "    total = len(mnist_test)\n",
    "\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        x1 = images.view(-1,28*28)\n",
    "        x2 = model.layer1(x1)\n",
    "        x3 = model.layer2(x2)\n",
    "        y  = model.layer3(x3)\n",
    "\n",
    "        pred = torch.argmax(y, dim = 1)\n",
    "        correct += torch.sum((pred == labels).float())\n",
    "\n",
    "    print('Testing Over!')\n",
    "    \n",
    "    accuracy = correct*100/total\n",
    "    print('The accuracy of the Multi-Layered Perceptron model is: {} %'.format(accuracy))\n",
    "    \n",
    "    d[l_r] = float(accuracy)\n",
    "    \n",
    "    if accuracy >= 97:\n",
    "        print('Accuracy Achieved! at {}.'.format(l_r))\n",
    "        break\n",
    "    elif l_r >= 1:\n",
    "        print('Learning rate limit reached')\n",
    "        break\n",
    "    \n",
    "    l_r += 0.05\n",
    "\n",
    "dict_sorted = dict(sorted(d.items(),key = op.itemgetter(1),reverse = True))\n",
    "print('\\n',dict_sorted,'\\n')\n",
    "for key,value in dict_sorted.items():\n",
    "    print('The best learning rate is', key)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd4feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: 11, 9: 10, 8: 9, 7: 8, 6: 7, 5: 6, 4: 5, 3: 4, 2: 3, 1: 2}\n",
      "{10: 11, 9: 10, 8: 9, 7: 8, 6: 7, 5: 6, 4: 5, 3: 4, 2: 3, 1: 2}\n",
      "The best learning rate is 11\n"
     ]
    }
   ],
   "source": [
    "import operator as op\n",
    "D = {}\n",
    "for i in range(10,0,-1):\n",
    "    D[i] = i+1\n",
    "sortkey = dict(sorted(D.items(), key = op.itemgetter(1), reverse = True))\n",
    "print(D)\n",
    "print(sortkey)\n",
    "for key,value in sortkey.items():\n",
    "    print('The best learning rate is', value)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
